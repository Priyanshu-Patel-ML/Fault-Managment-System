[2025-11-11T11:39:46.202+0000] {local_task_job_runner.py:123} INFO - ::group::Pre task execution logs
[2025-11-11T11:39:46.218+0000] {taskinstance.py:2612} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: Reinitialize_Application.apply_container_restart_docker manual__2025-11-11T11:39:44.426959+00:00 [queued]>
[2025-11-11T11:39:46.225+0000] {taskinstance.py:2612} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: Reinitialize_Application.apply_container_restart_docker manual__2025-11-11T11:39:44.426959+00:00 [queued]>
[2025-11-11T11:39:46.225+0000] {taskinstance.py:2865} INFO - Starting attempt 1 of 1
[2025-11-11T11:39:46.238+0000] {taskinstance.py:2888} INFO - Executing <Task(DockerOperator): apply_container_restart_docker> on 2025-11-11 11:39:44.426959+00:00
[2025-11-11T11:39:46.247+0000] {standard_task_runner.py:72} INFO - Started process 55 to run task
[2025-11-11T11:39:46.254+0000] {standard_task_runner.py:104} INFO - Running: ['***', 'tasks', 'run', 'Reinitialize_Application', 'apply_container_restart_docker', 'manual__2025-11-11T11:39:44.426959+00:00', '--job-id', '14537', '--raw', '--subdir', 'DAGS_FOLDER/dag_factory.py', '--cfg-path', '/tmp/tmpsx0jgjp2']
[2025-11-11T11:39:46.255+0000] {standard_task_runner.py:105} INFO - Job 14537: Subtask apply_container_restart_docker
[2025-11-11T11:39:46.311+0000] {task_command.py:467} INFO - Running <TaskInstance: Reinitialize_Application.apply_container_restart_docker manual__2025-11-11T11:39:44.426959+00:00 [running]> on host workflow.y2twbfvcjkaujnl2bmtbxunhcb.cx.internal.cloudapp.net
[2025-11-11T11:39:46.410+0000] {taskinstance.py:3131} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='Reinitialize_Application' AIRFLOW_CTX_TASK_ID='apply_container_restart_docker' AIRFLOW_CTX_EXECUTION_DATE='2025-11-11T11:39:44.426959+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2025-11-11T11:39:44.426959+00:00'
[2025-11-11T11:39:46.412+0000] {taskinstance.py:731} INFO - ::endgroup::
[2025-11-11T11:39:46.454+0000] {docker.py:367} INFO - Starting docker container from image priyanshu01ce/***_chaos:latest
[2025-11-11T11:39:46.909+0000] {docker.py:438} INFO - The container is run as root user. For security, consider using a regular user account.
[2025-11-11T11:39:56.101+0000] {docker.py:438} INFO - 
[2025-11-11T11:39:56.108+0000] {docker.py:438} INFO - total 9604
[2025-11-11T11:39:56.108+0000] {docker.py:438} INFO - drwxr-xr-x 6    1000 1000    4096 Nov 11 11:35 .
[2025-11-11T11:39:56.109+0000] {docker.py:438} INFO - drwxr-xr-x 1 *** root    4096 Sep 26 10:44 ..
[2025-11-11T11:39:56.110+0000] {docker.py:438} INFO - -rw-r--r-- 1    1000 1000    1193 Sep  8 07:02 API_Latency.json
[2025-11-11T11:39:56.110+0000] {docker.py:438} INFO - -rw-r--r-- 1    1000 1000     729 Sep  9 10:30 API_Timeout.json
[2025-11-11T11:39:56.111+0000] {docker.py:438} INFO - -rw-r--r-- 1    1000 1000    1331 Oct  7 18:22 Continuous_Load_Test_Azure.yaml
[2025-11-11T11:39:56.111+0000] {docker.py:438} INFO - -rw-r--r-- 1    1000 1000    1665 Nov 11 09:21 Memory_Stress_Test_Azure.yaml
[2025-11-11T11:39:56.111+0000] {docker.py:438} INFO - -rw-r--r-- 1    1000 1000    1178 Sep 30 18:19 Stress_Test_Azure.yaml
[2025-11-11T11:39:56.112+0000] {docker.py:438} INFO - drwxrwxr-x 2 root    root    4096 Oct 29 06:31 __pycache__
[2025-11-11T11:39:56.112+0000] {docker.py:438} INFO - drwxrwxr-x 5    1000 1000    4096 Oct 21 08:05 chaos_env
[2025-11-11T11:39:56.113+0000] {docker.py:438} INFO - -rw-r--r-- 1    1000 1000    8875 Sep 25 16:54 chaosk6_actions.py
[2025-11-11T11:39:56.113+0000] {docker.py:438} INFO - -rw-rw-r-- 1    1000 1000 9480876 Nov 11 11:29 chaostoolkit.log
[2025-11-11T11:39:56.113+0000] {docker.py:438} INFO - -rw-rw-r-- 1    1000 1000    1421 Oct 23 09:34 check.py
[2025-11-11T11:39:56.114+0000] {docker.py:438} INFO - -rw-r--r-- 1    1000 1000    3213 Sep  9 09:11 combined-sequential.json
[2025-11-11T11:39:56.114+0000] {docker.py:438} INFO - -rwxrwxr-x 1    1000 1000    1489 Oct 27 06:29 complete_chaos_mesh-cleanup.sh
[2025-11-11T11:39:56.115+0000] {docker.py:438} INFO - -rw-r--r-- 1    1000 1000     502 Sep 16 05:31 connection_test_experiment.json
[2025-11-11T11:39:56.115+0000] {docker.py:438} INFO - -rw-rw-r-- 1    1000 1000     692 Oct 24 01:43 container_probe.json
[2025-11-11T11:39:56.116+0000] {docker.py:438} INFO - -rw-rw-r-- 1    1000 1000    2533 Oct 23 09:28 container_probe.yaml
[2025-11-11T11:39:56.116+0000] {docker.py:438} INFO - -rw-r--r-- 1    1000 1000    1420 Sep 24 06:53 container_restart.json
[2025-11-11T11:39:56.116+0000] {docker.py:438} INFO - -rw-r--r-- 1    1000 1000   16452 Sep 26 09:59 container_restart.py
[2025-11-11T11:39:56.117+0000] {docker.py:438} INFO - -rw-r--r-- 1    1000 1000    1744 Nov 11 09:15 container_restart_Azure.yaml
[2025-11-11T11:39:56.117+0000] {docker.py:438} INFO - -rw-r--r-- 1    1000 1000    1409 Sep 18 12:30 continuous_load_test.json
[2025-11-11T11:39:56.118+0000] {docker.py:438} INFO - -rw-r--r-- 1    1000 1000    1637 Sep 25 10:13 cordon-uncordon-node.json
[2025-11-11T11:39:56.118+0000] {docker.py:438} INFO - -rw-r--r-- 1    1000 1000    1637 Sep 25 04:39 cordon_test.json
[2025-11-11T11:39:56.118+0000] {docker.py:438} INFO - -rw-r--r-- 1    1000 1000    1430 Nov 11 09:16 cordon_uncordon_node_Azure.yaml
[2025-11-11T11:39:56.119+0000] {docker.py:438} INFO - -rw-r--r-- 1    1000 1000    1203 Sep 30 06:51 cpu_stress_ng.json
[2025-11-11T11:39:56.119+0000] {docker.py:438} INFO - -rw-r--r-- 1    1000 1000    1760 Oct 21 08:00 db_cleanup.json
[2025-11-11T11:39:56.120+0000] {docker.py:438} INFO - -rw-r--r-- 1    1000 1000    6399 Sep 24 07:40 db_cleanup.py
[2025-11-11T11:39:56.120+0000] {docker.py:438} INFO - -rw-rw-r-- 1    1000 1000    5855 Oct 28 12:27 direct_memory_stress.py
[2025-11-11T11:39:56.120+0000] {docker.py:438} INFO - -rw-r--r-- 1    1000 1000    4084 Nov 11 11:29 journal.json
[2025-11-11T11:39:56.121+0000] {docker.py:438} INFO - -rw-rw-r-- 1    1000 1000       0 Nov 11 11:31 json
[2025-11-11T11:39:56.121+0000] {docker.py:438} INFO - -rw-rw-r-- 1 root    root   52013 Nov 11 10:41 k6_continuous_load.log
[2025-11-11T11:39:56.122+0000] {docker.py:438} INFO - -rw-r--r-- 1    1000 1000    3889 Nov 11 10:18 k6_continuous_summary.json
[2025-11-11T11:39:56.122+0000] {docker.py:438} INFO - -rw-r--r-- 1    1000 1000    3433 Sep 25 09:28 k6_summary.json
[2025-11-11T11:39:56.123+0000] {docker.py:438} INFO - -rw-r--r-- 1    1000 1000     989 Sep 30 09:24 kubernetes_actions.json
[2025-11-11T11:39:56.123+0000] {docker.py:438} INFO - -rw-r--r-- 1    1000 1000   10961 Sep 30 09:23 kubernetes_actions.py
[2025-11-11T11:39:56.123+0000] {docker.py:438} INFO - -rw-r--r-- 1    1000 1000     945 Sep 21 16:40 load_test.json
[2025-11-11T11:39:56.124+0000] {docker.py:438} INFO - -rw-r--r-- 1    1000 1000     528 Sep 17 12:13 max_connection_experiment.json
[2025-11-11T11:39:56.124+0000] {docker.py:438} INFO - -rw-r--r-- 1    1000 1000    1227 Sep 13 15:20 memory-stress-rollback.json
[2025-11-11T11:39:56.125+0000] {docker.py:438} INFO - -rw-rw-r-- 1    1000 1000    1066 Oct 30 12:27 memory_stress.json
[2025-11-11T11:39:56.125+0000] {docker.py:438} INFO - -rw-rw-r-- 1    1000 1000    6653 Oct 29 06:18 memory_stress.py
[2025-11-11T11:39:56.125+0000] {docker.py:438} INFO - -rw-r--r-- 1    1000 1000    1421 Sep 29 05:20 mongo_db_container_restart.json
[2025-11-11T11:39:56.126+0000] {docker.py:438} INFO - -rw-r--r-- 1    1000 1000    7586 Sep 18 05:54 mongodb_actions.py
[2025-11-11T11:39:56.126+0000] {docker.py:438} INFO - -rw-r--r-- 1    1000 1000    2136 Sep 18 11:23 mongodb_connection.json
[2025-11-11T11:39:56.127+0000] {docker.py:438} INFO - -rw-r--r-- 1    1000 1000     597 Sep 16 09:17 mongodb_network_latency_experiment.json
[2025-11-11T11:39:56.127+0000] {docker.py:438} INFO - -rw-r--r-- 1    1000 1000    3657 Sep 18 05:42 mongodb_probes.py
[2025-11-11T11:39:56.127+0000] {docker.py:438} INFO - -rw-r--r-- 1    1000 1000    6161 Sep 12 08:04 pod_restart.py
[2025-11-11T11:39:56.128+0000] {docker.py:438} INFO - -rw-r--r-- 1    1000 1000    1497 Sep 30 05:50 redis_config_faults.py
[2025-11-11T11:39:56.128+0000] {docker.py:438} INFO - -rw-r--r-- 1    1000 1000     862 Sep 30 05:50 redis_experiment.json
[2025-11-11T11:39:56.129+0000] {docker.py:438} INFO - -rw-r--r-- 1    1000 1000     945 Sep 18 06:53 redis_load.json
[2025-11-11T11:39:56.129+0000] {docker.py:438} INFO - -rw-r--r-- 1    1000 1000    1634 Nov 11 09:16 redis_memory_stress_Azure.yaml
[2025-11-11T11:39:56.129+0000] {docker.py:438} INFO - -rw-rw-r-- 1    1000 1000    1333 Oct 21 09:39 reinitialize_application.yaml
[2025-11-11T11:39:56.130+0000] {docker.py:438} INFO - -rw-r--r-- 1    1000 1000    1284 Sep 25 10:53 run_load_test_with_cleanup.py
[2025-11-11T11:39:56.130+0000] {docker.py:438} INFO - -rw-rw-r-- 1    1000 1000    1307 Oct 27 10:33 sample_probe.yaml
[2025-11-11T11:39:56.131+0000] {docker.py:438} INFO - drwxr-xr-x 2    1000 1000    4096 Oct 22 06:46 scripts
[2025-11-11T11:39:56.131+0000] {docker.py:438} INFO - -rw-rw-r-- 1    1000 1000     272 Oct 27 08:51 simple-stress-test.yaml
[2025-11-11T11:39:56.132+0000] {docker.py:438} INFO - drwxr-xr-x 4    1000 1000    4096 Sep 30 09:41 socialNetwork
[2025-11-11T11:39:56.132+0000] {docker.py:438} INFO - -rw-r--r-- 1    1000 1000     821 Sep 26 13:20 stress_test.json
[2025-11-11T11:39:56.133+0000] {docker.py:438} INFO - -rw-rw-r-- 1    1000 1000     301 Oct 27 08:46 test-stress-fixed.yaml
[2025-11-11T11:39:56.133+0000] {docker.py:438} INFO - -rw-rw-r-- 1    1000 1000     295 Oct 27 08:49 test_after_fix.yaml
[2025-11-11T11:39:56.133+0000] {docker.py:438} INFO - -rw-r--r-- 1    1000 1000     367 Sep 17 07:24 test_params.json
[2025-11-11T11:39:56.134+0000] {docker.py:438} INFO - Starting Reinitializing the Social Networking Application...
[2025-11-11T11:39:56.659+0000] {docker.py:438} INFO - [32m[2025-11-11 11:39:56 INFO] Validating the experiment's syntax
[2025-11-11T11:39:56.928+0000] {docker.py:438} INFO - [32m[2025-11-11 11:39:56 INFO] Experiment looks valid
[2025-11-11T11:39:56.929+0000] {docker.py:438} INFO - [32m[2025-11-11 11:39:56 INFO] Running experiment: Simple Social Network Reset
[2025-11-11T11:39:56.932+0000] {docker.py:438} INFO - [32m[2025-11-11 11:39:56 INFO] Steady-state strategy: default
[2025-11-11T11:39:56.932+0000] {docker.py:438} INFO - [32m[2025-11-11 11:39:56 INFO] Rollbacks strategy: default
[2025-11-11T11:39:56.933+0000] {docker.py:438} INFO - [32m[2025-11-11 11:39:56 INFO] No steady state hypothesis defined. That's ok, just exploring.
[2025-11-11T11:39:56.933+0000] {docker.py:438} INFO - [32m[2025-11-11 11:39:56 INFO] Playing your experiment's method now...
[2025-11-11T11:39:56.934+0000] {docker.py:438} INFO - [32m[2025-11-11 11:39:56 INFO] Action: complete-reset-and-reinit
[2025-11-11T11:39:56.934+0000] {docker.py:438} INFO - INFO:kubernetes_actions:Starting complete reset and reinitialization...
[2025-11-11T11:39:56.934+0000] {docker.py:438} INFO - INFO:kubernetes_actions:Starting full social network reset...
[2025-11-11T11:39:56.935+0000] {docker.py:438} INFO - INFO:kubernetes_actions:Clearing Redis data...
[2025-11-11T11:39:56.957+0000] {docker.py:438} INFO - INFO:kubernetes_actions:Loaded local Kubernetes config
[2025-11-11T11:39:56.971+0000] {docker.py:438} INFO - INFO:kubernetes_actions:Loaded local Kubernetes config
[2025-11-11T11:39:57.269+0000] {docker.py:438} INFO - INFO:kubernetes_actions:Found running pod: social-graph-redis-64bd79b48b-gpwdg for deployment: social-graph-redis
[2025-11-11T11:39:57.270+0000] {docker.py:438} INFO - INFO:kubernetes_actions:Executing command in pod social-graph-redis-64bd79b48b-gpwdg, container social-graph-redis: redis-cli FLUSHALL
[2025-11-11T11:39:58.714+0000] {docker.py:438} INFO - INFO:kubernetes_actions:Command executed successfully. Output: OK
[2025-11-11T11:39:58.731+0000] {docker.py:438} INFO - INFO:kubernetes_actions:Loaded local Kubernetes config
[2025-11-11T11:39:58.749+0000] {docker.py:438} INFO - INFO:kubernetes_actions:Loaded local Kubernetes config
[2025-11-11T11:39:59.087+0000] {docker.py:438} INFO - INFO:kubernetes_actions:Found running pod: home-timeline-redis-744dd9998f-xqjsk for deployment: home-timeline-redis
[2025-11-11T11:39:59.088+0000] {docker.py:438} INFO - INFO:kubernetes_actions:Executing command in pod home-timeline-redis-744dd9998f-xqjsk, container home-timeline-redis: redis-cli FLUSHALL
[2025-11-11T11:40:00.844+0000] {docker.py:438} INFO - INFO:kubernetes_actions:Command executed successfully. Output: OK
[2025-11-11T11:40:00.866+0000] {docker.py:438} INFO - INFO:kubernetes_actions:Loaded local Kubernetes config
[2025-11-11T11:40:00.913+0000] {docker.py:438} INFO - INFO:kubernetes_actions:Loaded local Kubernetes config
[2025-11-11T11:40:01.196+0000] {docker.py:438} INFO - INFO:kubernetes_actions:Found running pod: user-timeline-redis-7b8f6ff4fb-5s87m for deployment: user-timeline-redis
[2025-11-11T11:40:01.197+0000] {docker.py:438} INFO - INFO:kubernetes_actions:Executing command in pod user-timeline-redis-7b8f6ff4fb-5s87m, container user-timeline-redis: redis-cli FLUSHALL
[2025-11-11T11:40:02.579+0000] {docker.py:438} INFO - INFO:kubernetes_actions:Command executed successfully. Output: OK
[2025-11-11T11:40:02.579+0000] {docker.py:438} INFO - 
[2025-11-11T11:40:02.580+0000] {docker.py:438} INFO - INFO:kubernetes_actions:Clearing Memcached data...
[2025-11-11T11:40:02.596+0000] {docker.py:438} INFO - INFO:kubernetes_actions:Loaded local Kubernetes config
[2025-11-11T11:40:02.610+0000] {docker.py:438} INFO - INFO:kubernetes_actions:Loaded local Kubernetes config
[2025-11-11T11:40:02.877+0000] {docker.py:438} INFO - INFO:kubernetes_actions:Found running pod: post-storage-memcached-67c6cc65cc-j4jdz for deployment: post-storage-memcached
[2025-11-11T11:40:02.878+0000] {docker.py:438} INFO - INFO:kubernetes_actions:Executing command in pod post-storage-memcached-67c6cc65cc-j4jdz, container post-storage-memcached: sh -c echo 'flush_all' | nc localhost 11211
[2025-11-11T11:40:03.320+0000] {docker.py:438} INFO - INFO:kubernetes_actions:Command executed successfully. Output: sh: 1: nc: not found
[2025-11-11T11:40:03.335+0000] {docker.py:438} INFO - INFO:kubernetes_actions:Loaded local Kubernetes config
[2025-11-11T11:40:03.349+0000] {docker.py:438} INFO - INFO:kubernetes_actions:Loaded local Kubernetes config
[2025-11-11T11:40:03.598+0000] {docker.py:438} INFO - INFO:kubernetes_actions:Found running pod: user-memcached-56f89988c-kswck for deployment: user-memcached
[2025-11-11T11:40:03.599+0000] {docker.py:438} INFO - INFO:kubernetes_actions:Executing command in pod user-memcached-56f89988c-kswck, container user-memcached: sh -c echo 'flush_all' | nc localhost 11211
[2025-11-11T11:40:04.981+0000] {docker.py:438} INFO - INFO:kubernetes_actions:Command executed successfully. Output: sh: 1: nc: not found
[2025-11-11T11:40:04.982+0000] {docker.py:438} INFO - 
[2025-11-11T11:40:04.982+0000] {docker.py:438} INFO - INFO:kubernetes_actions:Dropping MongoDB databases...
[2025-11-11T11:40:04.998+0000] {docker.py:438} INFO - INFO:kubernetes_actions:Loaded local Kubernetes config
[2025-11-11T11:40:05.048+0000] {docker.py:438} INFO - INFO:kubernetes_actions:Loaded local Kubernetes config
[2025-11-11T11:40:05.380+0000] {docker.py:438} INFO - INFO:kubernetes_actions:Found running pod: post-storage-mongodb-7f7657964c-b2fld for deployment: post-storage-mongodb
[2025-11-11T11:40:05.381+0000] {docker.py:438} INFO - INFO:kubernetes_actions:Executing command in pod post-storage-mongodb-7f7657964c-b2fld, container post-storage-mongodb: mongo --eval db.getSiblingDB('post').dropDatabase()
[2025-11-11T11:40:06.996+0000] {docker.py:438} INFO - INFO:kubernetes_actions:Command executed successfully. Output: MongoDB shell version v4.4.6
[2025-11-11T11:40:06.997+0000] {docker.py:438} INFO - connecting to: mongodb://127.0.0.1:27017/?compressors=disabled&gssapiServiceName=mongodb
[2025-11-11T11:40:06.997+0000] {docker.py:438} INFO - Implicit session: session { "id" : UUID("192258fe-9de4-4dd9-a7dc-f2aa5940e669") }
[2025-11-11T11:40:06.998+0000] {docker.py:438} INFO - MongoDB server version: 4.4.6
[2025-11-11T11:40:06.998+0000] {docker.py:438} INFO - { "dropped" : "post", "ok" : 1 }
[2025-11-11T11:40:07.013+0000] {docker.py:438} INFO - INFO:kubernetes_actions:Loaded local Kubernetes config
[2025-11-11T11:40:07.030+0000] {docker.py:438} INFO - INFO:kubernetes_actions:Loaded local Kubernetes config
[2025-11-11T11:40:07.392+0000] {docker.py:438} INFO - INFO:kubernetes_actions:Found running pod: post-storage-mongodb-7f7657964c-b2fld for deployment: post-storage-mongodb
[2025-11-11T11:40:07.393+0000] {docker.py:438} INFO - INFO:kubernetes_actions:Executing command in pod post-storage-mongodb-7f7657964c-b2fld, container post-storage-mongodb: mongo --eval db.getSiblingDB('READ__ME_TO_RECOVER_YOUR_DATA').dropDatabase()
[2025-11-11T11:40:08.912+0000] {docker.py:438} INFO - INFO:kubernetes_actions:Command executed successfully. Output: MongoDB shell version v4.4.6
[2025-11-11T11:40:08.912+0000] {docker.py:438} INFO - connecting to: mongodb://127.0.0.1:27017/?compressors=disabled&gssapiServiceName=mongodb
[2025-11-11T11:40:08.913+0000] {docker.py:438} INFO - Implicit session: session { "id" : UUID("d3c588c2-9143-4ba3-879f-97acb2b24302") }
[2025-11-11T11:40:08.913+0000] {docker.py:438} INFO - MongoDB server version: 4.4.6
[2025-11-11T11:40:08.914+0000] {docker.py:438} INFO - { "ok" : 1 }
[2025-11-11T11:40:08.932+0000] {docker.py:438} INFO - INFO:kubernetes_actions:Loaded local Kubernetes config
[2025-11-11T11:40:08.951+0000] {docker.py:438} INFO - INFO:kubernetes_actions:Loaded local Kubernetes config
[2025-11-11T11:40:09.225+0000] {docker.py:438} INFO - INFO:kubernetes_actions:Found running pod: user-mongodb-f95b7d968-tqlld for deployment: user-mongodb
[2025-11-11T11:40:09.225+0000] {docker.py:438} INFO - INFO:kubernetes_actions:Executing command in pod user-mongodb-f95b7d968-tqlld, container user-mongodb: mongo --eval db.getSiblingDB('user').dropDatabase()
[2025-11-11T11:40:10.745+0000] {docker.py:438} INFO - INFO:kubernetes_actions:Command executed successfully. Output: MongoDB shell version v4.4.6
[2025-11-11T11:40:10.745+0000] {docker.py:438} INFO - connecting to: mongodb://127.0.0.1:27017/?compressors=disabled&gssapiServiceName=mongodb
[2025-11-11T11:40:10.746+0000] {docker.py:438} INFO - Implicit session: session { "id" : UUID("c88c6365-94e5-4292-8468-67fb93bda261") }
[2025-11-11T11:40:10.746+0000] {docker.py:438} INFO - MongoDB server version: 4.4.6
[2025-11-11T11:40:10.747+0000] {docker.py:438} INFO - { "dropped" : "user", "ok" : 1 }
[2025-11-11T11:40:10.765+0000] {docker.py:438} INFO - INFO:kubernetes_actions:Loaded local Kubernetes config
[2025-11-11T11:40:10.780+0000] {docker.py:438} INFO - INFO:kubernetes_actions:Loaded local Kubernetes config
[2025-11-11T11:40:11.012+0000] {docker.py:438} INFO - INFO:kubernetes_actions:Found running pod: user-mongodb-f95b7d968-tqlld for deployment: user-mongodb
[2025-11-11T11:40:11.013+0000] {docker.py:438} INFO - INFO:kubernetes_actions:Executing command in pod user-mongodb-f95b7d968-tqlld, container user-mongodb: mongo --eval db.getSiblingDB('READ__ME_TO_RECOVER_YOUR_DATA').dropDatabase()
[2025-11-11T11:40:12.550+0000] {docker.py:438} INFO - INFO:kubernetes_actions:Command executed successfully. Output: MongoDB shell version v4.4.6
[2025-11-11T11:40:12.550+0000] {docker.py:438} INFO - connecting to: mongodb://127.0.0.1:27017/?compressors=disabled&gssapiServiceName=mongodb
[2025-11-11T11:40:12.551+0000] {docker.py:438} INFO - Implicit session: session { "id" : UUID("ce70e287-1c58-4fa6-8f26-1c12a57b87ee") }
[2025-11-11T11:40:12.551+0000] {docker.py:438} INFO - MongoDB server version: 4.4.6
[2025-11-11T11:40:12.552+0000] {docker.py:438} INFO - { "ok" : 1 }
[2025-11-11T11:40:12.565+0000] {docker.py:438} INFO - INFO:kubernetes_actions:Loaded local Kubernetes config
[2025-11-11T11:40:12.579+0000] {docker.py:438} INFO - INFO:kubernetes_actions:Loaded local Kubernetes config
[2025-11-11T11:40:12.843+0000] {docker.py:438} INFO - INFO:kubernetes_actions:Found running pod: social-graph-mongodb-77fd77d9f4-jj4vn for deployment: social-graph-mongodb
[2025-11-11T11:40:12.846+0000] {docker.py:438} INFO - INFO:kubernetes_actions:Executing command in pod social-graph-mongodb-77fd77d9f4-jj4vn, container social-graph-mongodb: mongo --eval db.getSiblingDB('social-graph').dropDatabase()
[2025-11-11T11:40:14.351+0000] {docker.py:438} INFO - INFO:kubernetes_actions:Command executed successfully. Output: MongoDB shell version v4.4.6
[2025-11-11T11:40:14.351+0000] {docker.py:438} INFO - connecting to: mongodb://127.0.0.1:27017/?compressors=disabled&gssapiServiceName=mongodb
[2025-11-11T11:40:14.352+0000] {docker.py:438} INFO - Implicit session: session { "id" : UUID("868a1c10-ed4d-40fe-8c84-16889c15bdf0") }
[2025-11-11T11:40:14.352+0000] {docker.py:438} INFO - MongoDB server version: 4.4.6
[2025-11-11T11:40:14.352+0000] {docker.py:438} INFO - { "dropped" : "social-graph", "ok" : 1 }
[2025-11-11T11:40:14.366+0000] {docker.py:438} INFO - INFO:kubernetes_actions:Loaded local Kubernetes config
[2025-11-11T11:40:14.389+0000] {docker.py:438} INFO - INFO:kubernetes_actions:Loaded local Kubernetes config
[2025-11-11T11:40:14.668+0000] {docker.py:438} INFO - INFO:kubernetes_actions:Found running pod: social-graph-mongodb-77fd77d9f4-jj4vn for deployment: social-graph-mongodb
[2025-11-11T11:40:14.669+0000] {docker.py:438} INFO - INFO:kubernetes_actions:Executing command in pod social-graph-mongodb-77fd77d9f4-jj4vn, container social-graph-mongodb: mongo --eval db.getSiblingDB('READ__ME_TO_RECOVER_YOUR_DATA').dropDatabase()
[2025-11-11T11:40:16.251+0000] {docker.py:438} INFO - INFO:kubernetes_actions:Command executed successfully. Output: MongoDB shell version v4.4.6
[2025-11-11T11:40:16.252+0000] {docker.py:438} INFO - connecting to: mongodb://127.0.0.1:27017/?compressors=disabled&gssapiServiceName=mongodb
[2025-11-11T11:40:16.255+0000] {docker.py:438} INFO - Implicit session: session { "id" : UUID("81556219-db39-4bde-9156-50d0ab906b58") }
[2025-11-11T11:40:16.255+0000] {docker.py:438} INFO - MongoDB server version: 4.4.6
[2025-11-11T11:40:16.256+0000] {docker.py:438} INFO - { "ok" : 1 }
[2025-11-11T11:40:16.288+0000] {docker.py:438} INFO - INFO:kubernetes_actions:Loaded local Kubernetes config
[2025-11-11T11:40:16.310+0000] {docker.py:438} INFO - INFO:kubernetes_actions:Loaded local Kubernetes config
[2025-11-11T11:40:16.647+0000] {docker.py:438} INFO - INFO:kubernetes_actions:Found running pod: user-timeline-mongodb-6ff9797bfc-bnf8b for deployment: user-timeline-mongodb
[2025-11-11T11:40:16.648+0000] {docker.py:438} INFO - INFO:kubernetes_actions:Executing command in pod user-timeline-mongodb-6ff9797bfc-bnf8b, container user-timeline-mongodb: mongo --eval db.getSiblingDB('user-timeline').dropDatabase()
[2025-11-11T11:40:18.862+0000] {docker.py:438} INFO - INFO:kubernetes_actions:Command executed successfully. Output:
[2025-11-11T11:40:18.878+0000] {docker.py:438} INFO - INFO:kubernetes_actions:Loaded local Kubernetes config
[2025-11-11T11:40:18.894+0000] {docker.py:438} INFO - INFO:kubernetes_actions:Loaded local Kubernetes config
[2025-11-11T11:40:19.208+0000] {docker.py:438} INFO - INFO:kubernetes_actions:Found running pod: user-timeline-mongodb-6ff9797bfc-bnf8b for deployment: user-timeline-mongodb
[2025-11-11T11:40:19.209+0000] {docker.py:438} INFO - INFO:kubernetes_actions:Executing command in pod user-timeline-mongodb-6ff9797bfc-bnf8b, container user-timeline-mongodb: mongo --eval db.getSiblingDB('READ__ME_TO_RECOVER_YOUR_DATA').dropDatabase()
[2025-11-11T11:40:22.074+0000] {docker.py:438} INFO - INFO:kubernetes_actions:Command executed successfully. Output: MongoDB shell version v4.4.6
[2025-11-11T11:40:22.075+0000] {docker.py:438} INFO - connecting to: mongodb://127.0.0.1:27017/?compressors=disabled&gssapiServiceName=mongodb
[2025-11-11T11:40:22.075+0000] {docker.py:438} INFO - Error: couldn't connect to server 127.0.0.1:27017, connection attempt failed: SocketException: Error connecting to 127.0.0.1:27017 :: caused by :: Connection refused :
[2025-11-11T11:40:22.078+0000] {docker.py:438} INFO - connect@src/mongo/shell/mongo.js:374:17
[2025-11-11T11:40:22.079+0000] {docker.py:438} INFO - @(connect):2:6
[2025-11-11T11:40:22.079+0000] {docker.py:438} INFO - exception: connect failed
[2025-11-11T11:40:22.081+0000] {docker.py:438} INFO - exiting with code 1
[2025-11-11T11:40:22.081+0000] {docker.py:438} INFO - INFO:kubernetes_actions:Full social network reset completed
[2025-11-11T11:40:27.094+0000] {docker.py:438} INFO - INFO:kubernetes_actions:Loaded local Kubernetes config
[2025-11-11T11:40:27.095+0000] {docker.py:438} INFO - INFO:kubernetes_actions:Restarting deployment: social-graph-service
[2025-11-11T11:40:27.509+0000] {docker.py:438} INFO - INFO:kubernetes_actions:âœ… Successfully restarted social-graph-service
[2025-11-11T11:40:27.510+0000] {docker.py:438} INFO - INFO:kubernetes_actions:Restarting deployment: user-service
[2025-11-11T11:40:27.686+0000] {docker.py:438} INFO - INFO:kubernetes_actions:âœ… Successfully restarted user-service
[2025-11-11T11:40:27.687+0000] {docker.py:438} INFO - INFO:kubernetes_actions:Restarting deployment: post-storage-service
[2025-11-11T11:40:27.882+0000] {docker.py:438} INFO - INFO:kubernetes_actions:âœ… Successfully restarted post-storage-service
[2025-11-11T11:40:27.882+0000] {docker.py:438} INFO - INFO:kubernetes_actions:Restarting deployment: compose-post-service
[2025-11-11T11:40:28.060+0000] {docker.py:438} INFO - INFO:kubernetes_actions:âœ… Successfully restarted compose-post-service
[2025-11-11T11:40:28.061+0000] {docker.py:438} INFO - INFO:kubernetes_actions:Restarting deployment: home-timeline-service
[2025-11-11T11:40:28.284+0000] {docker.py:438} INFO - INFO:kubernetes_actions:âœ… Successfully restarted home-timeline-service
[2025-11-11T11:40:28.285+0000] {docker.py:438} INFO - INFO:kubernetes_actions:Restarting deployment: user-timeline-service
[2025-11-11T11:40:28.478+0000] {docker.py:438} INFO - INFO:kubernetes_actions:âœ… Successfully restarted user-timeline-service
[2025-11-11T11:40:28.479+0000] {docker.py:438} INFO - INFO:kubernetes_actions:Restarting deployment: nginx-thrift
[2025-11-11T11:40:28.728+0000] {docker.py:438} INFO - INFO:kubernetes_actions:âœ… Successfully restarted nginx-thrift
[2025-11-11T11:40:28.729+0000] {docker.py:438} INFO - INFO:kubernetes_actions:Restarting deployment: text-service
[2025-11-11T11:40:28.920+0000] {docker.py:438} INFO - INFO:kubernetes_actions:âœ… Successfully restarted text-service
[2025-11-11T11:40:28.921+0000] {docker.py:438} INFO - INFO:kubernetes_actions:Restarting deployment: unique-id-service
[2025-11-11T11:40:29.118+0000] {docker.py:438} INFO - INFO:kubernetes_actions:âœ… Successfully restarted unique-id-service
[2025-11-11T11:40:29.119+0000] {docker.py:438} INFO - INFO:kubernetes_actions:Restarting deployment: user-mention-service
[2025-11-11T11:40:29.328+0000] {docker.py:438} INFO - INFO:kubernetes_actions:âœ… Successfully restarted user-mention-service
[2025-11-11T11:40:29.329+0000] {docker.py:438} INFO - INFO:kubernetes_actions:Waiting 90 seconds for services to restart...
[2025-11-11T11:41:59.329+0000] {docker.py:438} INFO - INFO:kubernetes_actions:Reinitializing social network data...
[2025-11-11T11:50:11.239+0000] {docker.py:438} INFO - INFO:kubernetes_actions:Social network reinitialization completed successfully
[2025-11-11T11:50:11.240+0000] {docker.py:438} INFO - [32m[2025-11-11 11:50:11 INFO] Let's rollback...
[2025-11-11T11:50:11.241+0000] {docker.py:438} INFO - [32m[2025-11-11 11:50:11 INFO] No declared rollbacks, let's move on.
[2025-11-11T11:50:11.243+0000] {docker.py:438} INFO - [32m[2025-11-11 11:50:11 INFO] Experiment ended with status: completed
[2025-11-11T11:50:11.359+0000] {docker.py:438} INFO - Reinitialized Social Networking APplication successfully
[2025-11-11T11:50:11.599+0000] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2025-11-11T11:50:11.600+0000] {taskinstance.py:352} INFO - Marking task as SUCCESS. dag_id=Reinitialize_Application, task_id=apply_container_restart_docker, run_id=manual__2025-11-11T11:39:44.426959+00:00, execution_date=20251111T113944, start_date=20251111T113946, end_date=20251111T115011
[2025-11-11T11:50:11.644+0000] {local_task_job_runner.py:266} INFO - Task exited with return code 0
[2025-11-11T11:50:11.663+0000] {taskinstance.py:3900} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2025-11-11T11:50:11.667+0000] {local_task_job_runner.py:245} INFO - ::endgroup::
